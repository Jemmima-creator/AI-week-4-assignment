# AI-week-4-assignment
Overview of AI Tools and Applications – README

Student: Jemmimah Mwithalii
Course: Artificial Intelligence

Institution: PLP

---

Overview

The assignment showcases my understanding and application of AI tools and frameworks in software engineering. It encompasses three major parts: Theoretical Analysis, Practical Implementation, and Ethical Reflection, in addition to a Bonus Innovation Challenge. In each section, one will see just how AI works to enhance the efficiency of software development, testing, prediction, and decision-making.

---

## Part 1: Theoretical Analysis 

1. Short Answer Questions**

I have discussed how AI-driven code generation tools like GitHub Copilot reduce development time by suggesting code snippets, optimizing syntax, and helping developers focus on logic rather than boilerplate code. Their limitations include dependency on training data and giving wrong suggestions.

I've compared **supervised vs. unsupervised learning** in the context of automated bug detection: supervised learning is used to predict known bug types using labeled data, while unsupervised methods detect new unseen anomalies.

Lastly, I explained why **bias mitigation** is critical in AI-driven personalization for ensuring fairness, non-discrimination, and increasing inclusivity in user experiences.

2. Case Study Analysis – AI in DevOps

The case study on **AIOps** taught me how AI automates the deployment pipelines through detecting performance issues and optimizing resource utilization. Examples include:
Predicting Deployment Failures Using Machine Learning.

- Automate incident response by applying anomaly detection tools.

This improves software reliability, reduces downtime, and ensures faster, error-free releases.

PRESS

## Part 2: Practical Implementation 
Tasks: **1.** AI code completion

Using **GitHub Copilot**, I implemented a Python function that sorts a list of dictionaries by a certain key. I then compared this AI-generated code with my manual version.

Its solution was more concise and effective, handling edge cases automatically. This task demonstrated that AI tools greatly enhance productivity while human review is still necessary in order to validate the logic.

Deliverable: Code snippets and a 200-word efficiency analysis.
---
**Task 2: Automated Testing with AI

In this context, I applied **Selenium IDE** with AI capabilities to automate the test cases for login both for valid and invalid credentials. This AI feature further improved test coverage by learning from previous runs and generating better test inputs automatically.

Upon running the tests, I recorded a **success rate of 100%**, with two valid logins and zero failed attempts.

The AI's ability to adapt and create reusable test cases really showed how automated testing enhances the accuracy, reduces human error, and increases efficiency.
Deliverable: Test script, execution screenshots, and a 150-word summary.

---

Task 3: Predictive Analytics for Resource Allocation

Using the **Kaggle Breast Cancer Dataset**, I developed a **Random Forest Classifier** model that predicts the priority of an issue: high, medium, or low. I cleaned and labeled the data, removed columns not needed, and split it into training and test sets.

The model gave strong results with high **accuracy and F1-score**, thus confirming its reliability for predictive analysis.
Deliverable: Jupyter Notebook and performance metrics.

Summary:

I learned how pre-processing, feature selection, and evaluation metrics such as accuracy, precision, recall, and F1-score affect the model performance. This task strengthened my understanding of machine learning pipelines and model evaluation.

---
## Part 3: Ethical Reflection 
I reflected on the possible biases in the dataset, such as the underrepresentation of certain categories of data that may make model predictions biased.

To address this, I explored the use of **IBM AI Fairness 360 (AIF360)**, a fairness toolkit that can detect, measure, and mitigate bias through pre-processing, in-processing, and post-processing algorithms.

Such tools guarantee AI deployment that is transparent, accountable, and of ethical integrity.

-
Bonus Task  – Innovation Challenge I proposed **CodeDoc AI**, a completely new tool for **automated documentation generation** in software engineering. The tool utilizes Natural Language Processing combined with machine learning models for codebase analysis, summarization of functions, and automatic generation of human-readable documentation. This will help save developers' time, keep the project records current, and improve code collaboration and readability. **Deliverable:** 1-page proposal outlining the issue, workflow, and possible impact. ---
Some of the advantages of using CPR methods are as follows: Conclusion This homework helped me integrate both theoretical and practical aspects of AI into real software development. I did hands-on work with AI tools like GitHub Copilot, Selenium, and Random Forest models and also became more aware of the ethics in AI applications. Overall, this deepened my understanding of how AI can optimize, automate, and innovate the whole software engineering lifecycle.
